#!/bin/sh

# Make sure to:
# 1) Name this file `backup.sh` and place it in /home/ubuntu
# 2) Run sudo apt-get install awscli to install the AWSCLI
# 3) Run aws configure (enter s3-authorized IAM user and specify region)
# 4) Fill in DB host + name
# 5) Create S3 bucket for the backups and fill it in below (set a lifecycle rule to expire files older than X days in the bucket)
# 6) Run chmod +x backup.sh
# 7) Test it out via ./backup.sh
# 8) Set up a daily backup at midnight via `crontab -e`:
#    0 0 * * * /home/ubuntu/backup.sh > /home/ubuntu/backup.log

# DB host (secondary preferred as to avoid impacting primary performance)
HOST=bpprod.co2fks9r7q11.us-east-1.rds.amazonaws.com

# DB name
DBNAME="DB Name"

# S3 bucket name
BUCKET="bucketname"

#DB user account
USER="User Name of db"

# Current time
TIME=`/bin/date +%d-%m-%Y-%T`

# zip file of backup directory
FILE=$TIME.sql

ZIP=$TIME.zip 
# Log
echo "Backing up $HOST/$DBNAME to s3://$BUCKET/ on $TIME";

# Dump from localhost into backup 
PGPASSWORD="DB password" pg_dump -Fc --no-acl -h $HOST -U $USER $DBNAME > $FILE

# Create zip of backup directory  
zip $ZIP $FILE

# Upload tar to s3 
aws s3 cp $ZIP s3://$BUCKET/

#remove the zip file from local
sudo rm -rf *.zip

#remove the sql file from local

sudo rm -rf *.sql

